{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#import os\n",
    "#print(os.listdir('input/'))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial of machine learning with PySpark. I will create a classification model and a regression model using Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Spark\n",
    "Uncommet the code below to install PySpark and sparkmagic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sparkmagic\n",
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "We'll train a **LogisticRegression** model with a **Pipleline** preparing the data, a **CrossValidator** to tuene the parameters of the model, and a **BinaryClassificationEvaluator** to evaluate our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 13:23:12 WARN Utils: Your hostname, MacBook-Air-de-Mauricio-5.local resolves to a loopback address: 127.0.0.1; using 192.168.100.74 instead (on interface en0)\n",
      "23/09/21 13:23:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/21 13:23:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "The data from the flight.csv file data includes specific characteristics (or features) for each flight, as well as a column indicating how many minutes late or early the flight arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 13:23:24 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "csv = spark.read.csv('flights.csv', inferSchema=True, header=True)\n",
    "csv.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for a Classification Model (Decision Tree Learning Model)\n",
    "I select a subset of columns to use as features and create a Boolean label field named *label* with values 1 or 0. Specifically, **1** for flight that arrived late, **0** for flight was early or on-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|label|\n",
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|    0|\n",
      "|        19|        5|     DL|          14869|        12478|       0|    0|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|    0|\n",
      "|        19|        5|     DL|          15016|        11433|      28|    1|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|    0|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|    0|\n",
      "|        19|        5|     DL|          15016|        10397|       0|    0|\n",
      "|        19|        5|     DL|          10397|        14869|      15|    1|\n",
      "|        19|        5|     DL|          10397|        10423|      33|    1|\n",
      "|        19|        5|     DL|          11278|        10397|     323|    1|\n",
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))\n",
    "data.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "I will use 70% of the data for training, and reserve 30% for testing. In the testing data, the *label* column is renamed to *trueLabel* so I can use it later to compare predicted labels with known actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1891380  Testing Rows: 810838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    splits = data.randomSplit([0.7, 0.3])\n",
    "    train = splits[0]\n",
    "    test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "    train_rows = train.count()\n",
    "    test_rows = test.count()\n",
    "    print(\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "\n",
    "A pipeline consists of a series of transformer and estimator stages that typically prepare a DataFrame for modeling and then train a predictive model. In this case, you will create a pipeline with seven stages:\n",
    "* A **StringIndexer estimator** that converts string values to indexes for categorical features\n",
    "* A **VectorAssembler** that combines categorical features into a single vector\n",
    "* A **VectorIndexer** that creates indexes for a vector of categorical features\n",
    "* A **VectorAssembler** that creates a vector of continuous numeric features\n",
    "* A **MinMaxScaler** that normalizes continuous numeric features\n",
    "* A **VectorAssembler** that creates a vector of categorical and continuous features\n",
    "* A **DecisionTreeClassifier** that trains a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCol = \"Carrier\", outputCol = \"CarrierIdx\")\n",
    "catVect = VectorAssembler(inputCols = [\"CarrierIdx\", \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\"], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = [\"DepDelay\"], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "#dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline to train a model\n",
    "Run the pipeline as an Estimator on the training data to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 13:23:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/09/21 13:23:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "piplineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate label predictions\n",
    "Transform the test data with all of the stages and the trained model in the pipeline to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+----------+---------+\n",
      "|features                                           |prediction|trueLabel|\n",
      "+---------------------------------------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,10397.0,12264.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,10397.0,12264.0,0.04205607476635514] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,10397.0,12264.0,0.04465212876427829] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,10423.0,13487.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10529.0,11193.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10529.0,11193.0,0.037383177570093455]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10529.0,11433.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10693.0,10397.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10693.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10721.0,12478.0,0.03115264797507788] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10721.0,12478.0,0.05192107995846314] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10792.0,11433.0,0.028037383177570093]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10821.0,11193.0,0.05659397715472482] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10821.0,12478.0,0.029595015576323987]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,10821.0,12478.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10821.0,14492.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,11193.0,0.028037383177570093]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,11193.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,13244.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,13244.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11066.0,13487.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11066.0,13487.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,10821.0,0.03426791277258567] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,11057.0,0.033229491173416406]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,11278.0,0.05088265835929387] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,11298.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,11433.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13198.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13198.0,0.0347871235721703]  |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,13342.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13930.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,14122.0,0.049325025960539975]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,14492.0,0.04620976116303219] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11278.0,11193.0,0.040498442367601244]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11278.0,11193.0,0.056074766355140186]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,11278.0,13244.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11298.0,12478.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11298.0,13244.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10423.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10792.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11042.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11042.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11193.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11193.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11298.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,12264.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,12266.0,0.033229491173416406]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,11433.0,13232.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13342.0,0.0347871235721703]  |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13851.0,0.033229491173416406]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13871.0,0.035306334371754934]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13930.0,0.036344755970924195]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13931.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13931.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13931.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14100.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14100.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14122.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14307.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14307.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14307.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14307.0,0.04257528556593977] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11433.0,14492.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11618.0,11193.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12191.0,10397.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12264.0,10397.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12264.0,12478.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12264.0,12478.0,0.049325025960539975]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12266.0,13487.0,0.0430944963655244]  |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.029595015576323987]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12339.0,12478.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,13487.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,13487.0,0.037383177570093455]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,14492.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,10721.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,10721.0,0.032191069574247146]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,10721.0,0.033229491173416406]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,10721.0,0.033229491173416406]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11057.0,0.047248182762201454]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,11193.0,0.028037383177570093]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,11278.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11298.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11433.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,12451.0,0.04361370716510903] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,13487.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,13930.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14122.0,0.04465212876427829] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,14492.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13198.0,11193.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13198.0,12478.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13198.0,13244.0,0.028037383177570093]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13204.0,14492.0,0.142263759086189]   |1.0       |1        |\n",
      "|[10.0,1.0,0.0,13232.0,11433.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,10423.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,11193.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,11278.0,0.03842159916926272] |0.0       |0        |\n",
      "+---------------------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = piplineModel.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "predicted.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the results, some trueLabel 1s are predicted as 0. Let's evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Classification Model\n",
    "We'll calculate a *Confusion Matrix* and the *Area Under ROC* (Receiver Operating Characteristic) to evaluate the model. \n",
    "### Compute Confusion Matrix\n",
    "Classifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\n",
    "- True Positives\n",
    "- True Negatives\n",
    "- False Positives\n",
    "- False Negatives\n",
    "\n",
    "From these core measures, other evaluation metrics such as *precision*, *recall* and *F1* can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|   metric|              value|\n",
      "+---------+-------------------+\n",
      "|       TP|            19328.0|\n",
      "|       FP|               81.0|\n",
      "|       TN|           649193.0|\n",
      "|       FN|           142236.0|\n",
      "|Precision| 0.9958266783450976|\n",
      "|   Recall|0.11963061077962912|\n",
      "|       F1|0.21360092389472463|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "metrics = spark.createDataFrame([\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "metrics.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we've got a good *Precision*, but a low *Recall*, therefore our *F1* is not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Area Under ROC\n",
    "Another way to assess the performance of a classification model is to measure the area under a ROC (Receiver Operating Characteristic) curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that we can use to compute this. The ROC curve shows the True Positive and False Positive rates plotted for varying thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.9230568804607274\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(prediction)\n",
    "print (\"AUR = \", aur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the AUR shows that our model is ok.\n",
    "Let's look deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Raw Prediction and Probability\n",
    "The prediction is based on a raw prediction score that describes a labelled point in a logistic function. This raw prediction is then converted to a predicted label of 0 or 1 based on a probability vector that indicates the confidence for each possible label value (in this case, 0 and 1). The value with the highest confidence is selected as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "|rawPrediction                           |probability                             |prediction|trueLabel|\n",
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "|[1.5989348820872658,-1.5989348820872658]|[0.8318694675666443,0.16813053243335574]|0.0       |0        |\n",
      "|[1.3056424336606864,-1.3056424336606864]|[0.7867830638033272,0.2132169361966728] |0.0       |0        |\n",
      "|[1.2358108983210248,-1.2358108983210248]|[0.7748339988514431,0.2251660011485569] |0.0       |0        |\n",
      "|[1.6977955746919835,-1.6977955746919835]|[0.845246604948976,0.15475339505102403] |0.0       |0        |\n",
      "|[1.6272461145895942,-1.6272461145895942]|[0.8357920347491233,0.16420796525087666]|0.0       |0        |\n",
      "|[1.4317178156385415,-1.4317178156385415]|[0.8071688302402809,0.19283116975971915]|0.0       |0        |\n",
      "|[1.6274171604773495,-1.6274171604773495]|[0.8358155083729516,0.1641844916270484] |0.0       |0        |\n",
      "|[1.6280975498577341,-1.6280975498577341]|[0.8359088554769273,0.16409114452307272]|0.0       |0        |\n",
      "|[1.616333458594648,-1.616333458594648]  |[0.8342888480265201,0.16571115197347985]|0.0       |0        |\n",
      "|[1.6018902695761574,-1.6018902695761574]|[0.8322824105955454,0.16771758940445458]|0.0       |1        |\n",
      "|[1.0432379868588635,-1.0432379868588635]|[0.7394742944671646,0.2605257055328354] |0.0       |1        |\n",
      "|[1.6855575591920342,-1.6855575591920342]|[0.8436390418975532,0.15636095810244677]|0.0       |0        |\n",
      "|[0.917490498875398,-0.917490498875398]  |[0.7145305017316467,0.2854694982683533] |0.0       |1        |\n",
      "|[1.6446542745985688,-1.6446542745985688]|[0.8381672508432719,0.16183274915672807]|0.0       |1        |\n",
      "|[1.6167216604627042,-1.6167216604627042]|[0.8343425103452985,0.1656574896547015] |0.0       |0        |\n",
      "|[1.6600559417412455,-1.6600559417412455]|[0.8402455124265262,0.15975448757347377]|0.0       |0        |\n",
      "|[1.687678985423607,-1.687678985423607]  |[0.843918679955361,0.15608132004463904] |0.0       |0        |\n",
      "|[1.5899148359480804,-1.5899148359480804]|[0.830604120743298,0.16939587925670196] |0.0       |0        |\n",
      "|[1.6193091797330519,-1.6193091797330519]|[0.8346998352157655,0.16530016478423448]|0.0       |0        |\n",
      "|[1.6053428726651195,-1.6053428726651195]|[0.8327638011868239,0.16723619881317608]|0.0       |0        |\n",
      "|[1.6335265283060116,-1.6335265283060116]|[0.8366521652565833,0.16334783474341674]|0.0       |0        |\n",
      "|[1.6055939141701467,-1.6055939141701467]|[0.8327987603779763,0.1672012396220237] |0.0       |0        |\n",
      "|[1.520994693475714,-1.520994693475714]  |[0.8206849075639735,0.1793150924360265] |0.0       |0        |\n",
      "|[1.5490955027345377,-1.5490955027345377]|[0.824783055936341,0.17521694406365895] |0.0       |0        |\n",
      "|[1.0743985671798122,-1.0743985671798122]|[0.7454325013456968,0.25456749865430317]|0.0       |1        |\n",
      "|[1.605132489585221,-1.605132489585221]  |[0.8327344994516618,0.16726550054833822]|0.0       |0        |\n",
      "|[1.6471276241008803,-1.6471276241008803]|[0.8385024626243776,0.16149753737562245]|0.0       |0        |\n",
      "|[1.7042507523388082,-1.7042507523388082]|[0.8460890925353097,0.15391090746469027]|0.0       |0        |\n",
      "|[1.5087224533877555,-1.5087224533877555]|[0.8188717973280405,0.1811282026719595] |0.0       |1        |\n",
      "|[1.6065892303959348,-1.6065892303959348]|[0.8329373072672867,0.16706269273271335]|0.0       |0        |\n",
      "|[1.6625577988915161,-1.6625577988915161]|[0.8405810583884765,0.15941894161152348]|0.0       |0        |\n",
      "|[1.6485914918235838,-1.6485914918235838]|[0.838700595642304,0.16129940435769596] |0.0       |0        |\n",
      "|[1.6346251847556514,-1.6346251847556514]|[0.8368022579622878,0.1631977420377122] |0.0       |0        |\n",
      "|[1.620974599888867,-1.620974599888867]  |[0.8349294951918096,0.1650705048081904] |0.0       |0        |\n",
      "|[1.1183243821535065,-1.1183243821535065]|[0.7536777742832974,0.2463222257167026] |0.0       |1        |\n",
      "|[1.2023859203047231,-1.2023859203047231]|[0.7689489534991361,0.23105104650086394]|0.0       |1        |\n",
      "|[1.354399451032368,-1.354399451032368]  |[0.7948479539230646,0.20515204607693538]|0.0       |0        |\n",
      "|[0.9354102389943975,-0.9354102389943975]|[0.7181716154571833,0.28182838454281667]|0.0       |1        |\n",
      "|[1.607254707904257,-1.607254707904257]  |[0.8330298897760439,0.16697011022395614]|0.0       |0        |\n",
      "|[1.6348144173454262,-1.6348144173454262]|[0.8368280987198993,0.16317190128010073]|0.0       |0        |\n",
      "|[1.6632929529397091,-1.6632929529397091]|[0.8406795477063482,0.15932045229365177]|0.0       |0        |\n",
      "|[1.6484840071545852,-1.6484840071545852]|[0.8386860543819987,0.16131394561800128]|0.0       |0        |\n",
      "|[1.6068480690032116,-1.6068480690032116]|[0.832973322267281,0.16702667773271895] |0.0       |0        |\n",
      "|[1.6768577771426183,-1.6768577771426183]|[0.8424880005547621,0.15751199944523786]|0.0       |0        |\n",
      "|[1.5930599347350243,-1.5930599347350243]|[0.8310461790125843,0.16895382098741574]|0.0       |0        |\n",
      "|[1.5792012440381376,-1.5792012440381376]|[0.8290913649074432,0.17090863509255683]|0.0       |0        |\n",
      "|[1.5652349369702054,-1.5652349369702054]|[0.827103249486376,0.17289675051362396] |0.0       |0        |\n",
      "|[1.593242383681963,-1.593242383681963]  |[0.8310717948350558,0.16892820516494422]|0.0       |0        |\n",
      "|[1.593930843380177,-1.593930843380177]  |[0.8311684266727559,0.16883157332724408]|0.0       |0        |\n",
      "|[1.552033347558778,-1.552033347558778]  |[0.8252072163978059,0.17479278360219408]|0.0       |1        |\n",
      "|[1.678418570868383,-1.678418570868383]  |[0.8426950102564104,0.15730498974358964]|0.0       |0        |\n",
      "|[1.5109012820850825,-1.5109012820850825]|[0.8191947383965293,0.18080526160347066]|0.0       |0        |\n",
      "|[1.5531629631091601,-1.5531629631091601]|[0.8253700925943486,0.17462990740565143]|0.0       |0        |\n",
      "|[1.4973119886614104,-1.4973119886614104]|[0.8171732265567055,0.18282677344329445]|0.0       |0        |\n",
      "|[1.4694214233062852,-1.4694214233062852]|[0.8129694292961787,0.18703057070382134]|0.0       |0        |\n",
      "|[1.6370178208126727,-1.6370178208126727]|[0.8371287432323452,0.1628712567676548] |0.0       |0        |\n",
      "|[1.6370178208126727,-1.6370178208126727]|[0.8371287432323452,0.1628712567676548] |0.0       |0        |\n",
      "|[1.6230515137447403,-1.6230515137447403]|[0.835215541015759,0.164784458984241]   |0.0       |0        |\n",
      "|[1.6231719585573678,-1.6231719585573678]|[0.8352321172312046,0.1647678827687954] |0.0       |0        |\n",
      "|[1.6092056514894355,-1.6092056514894355]|[0.8333010723712877,0.1666989276287123] |0.0       |0        |\n",
      "|[1.6231876377637453,-1.6231876377637453]|[0.8352342749832696,0.16476572501673037]|0.0       |0        |\n",
      "|[1.637285792703489,-1.637285792703489]  |[0.8371652763475733,0.16283472365242668]|0.0       |0        |\n",
      "|[1.6233194856355566,-1.6233194856355566]|[0.8352524188191885,0.16474758118081145]|0.0       |0        |\n",
      "|[1.5674542573638273,-1.5674542573638273]|[0.8274203896336988,0.1725796103663012] |0.0       |0        |\n",
      "|[1.3020944230731124,-1.3020944230731124]|[0.7861872599934036,0.21381274000659645]|0.0       |1        |\n",
      "|[1.6234513335073677,-1.6234513335073677]|[0.8352705610511794,0.16472943894882064]|0.0       |0        |\n",
      "|[1.6366668773743034,-1.6366668773743034]|[0.8370808884649596,0.16291911153504035]|0.0       |0        |\n",
      "|[1.6270901983926431,-1.6270901983926431]|[0.8357706351115548,0.1642293648884452] |0.0       |0        |\n",
      "|[1.5858227883764344,-1.5858227883764344]|[0.8300275867460759,0.1699724132539241] |0.0       |0        |\n",
      "|[1.5733395916935782,-1.5733395916935782]|[0.8282591724406657,0.17174082755933429]|0.0       |0        |\n",
      "|[1.1264177655197432,-1.1264177655197432]|[0.7551772046920446,0.24482279530795537]|0.0       |1        |\n",
      "|[1.2947498574310736,-1.2947498574310736]|[0.7849500667068289,0.21504993329317112]|0.0       |0        |\n",
      "|[1.7129067129339288,-1.7129067129339288]|[0.8472129182797736,0.15278708172022637]|0.0       |0        |\n",
      "|[1.6570414846621995,-1.6570414846621995]|[0.8398404576958562,0.16015954230414375]|0.0       |1        |\n",
      "|[1.6438199398972007,-1.6438199398972007]|[0.8380540473228797,0.1619459526771203] |0.0       |0        |\n",
      "|[1.6724716594528353,-1.6724716594528353]|[0.8419050793735652,0.15809492062643482]|0.0       |0        |\n",
      "|[1.4490107463659179,-1.4490107463659179]|[0.8098461401988384,0.19015385980116162]|0.0       |0        |\n",
      "|[1.7150868353116067,-1.7150868353116067]|[0.8474949067060537,0.15250509329394635]|0.0       |0        |\n",
      "|[1.6437702079684677,-1.6437702079684677]|[0.838047297618838,0.161952702381162]   |0.0       |0        |\n",
      "|[1.5879049796967382,-1.5879049796967382]|[0.8303211441957654,0.16967885580423459]|0.0       |1        |\n",
      "|[1.5599723655608737,-1.5599723655608737]|[0.8263493875831461,0.17365061241685387]|0.0       |0        |\n",
      "|[1.5599723655608737,-1.5599723655608737]|[0.8263493875831461,0.17365061241685387]|0.0       |0        |\n",
      "|[1.183121538969557,-1.183121538969557]  |[0.7655086005183228,0.2344913994816772] |0.0       |1        |\n",
      "|[1.6999718264861152,-1.6999718264861152]|[0.8455310552578187,0.1544689447421813] |0.0       |1        |\n",
      "|[1.602268255762502,-1.602268255762502]  |[0.8323351664557043,0.16766483354429573]|0.0       |0        |\n",
      "|[1.658147737858211,-1.658147737858211]  |[0.8399892021776901,0.16001079782230987]|0.0       |0        |\n",
      "|[1.5884124158304114,-1.5884124158304114]|[0.8303926238454514,0.16960737615454857]|0.0       |0        |\n",
      "|[1.2818791799764608,-1.2818791799764608]|[0.7827694846428237,0.2172305153571763] |0.0       |0        |\n",
      "|[1.5759099764851827,-1.5759099764851827]|[0.8286244907397505,0.17137550926024947]|0.0       |0        |\n",
      "|[1.5762256986863306,-1.5762256986863306]|[0.8286693205173501,0.1713306794826499] |0.0       |0        |\n",
      "|[1.2551374728340907,-1.2551374728340907]|[0.7781879152220654,0.22181208477793457]|0.0       |1        |\n",
      "|[1.6883566876836158,-1.6883566876836158]|[0.8440079260530542,0.1559920739469458] |0.0       |0        |\n",
      "|[1.6922341229122055,-1.6922341229122055]|[0.8445177428733014,0.1554822571266986] |0.0       |0        |\n",
      "|[1.6372847028311646,-1.6372847028311646]|[0.837165127776585,0.16283487222341497] |0.0       |0        |\n",
      "|[1.7076621596292445,-1.7076621596292445]|[0.8465328096701248,0.1534671903298752] |0.0       |0        |\n",
      "|[-1.3639840516704291,1.3639840516704291]|[0.20359355243567645,0.7964064475643235]|1.0       |1        |\n",
      "|[1.6647666831624246,-1.6647666831624246]|[0.8408768362798082,0.15912316372019175]|0.0       |0        |\n",
      "|[1.6641506751096893,-1.6641506751096893]|[0.8407943952565196,0.15920560474348044]|0.0       |0        |\n",
      "|[1.5809016049253093,-1.5809016049253093]|[0.8293321693238432,0.17066783067615676]|0.0       |0        |\n",
      "|[1.4273328059299666,-1.4273328059299666]|[0.806485395827125,0.19351460417287503] |0.0       |0        |\n",
      "+----------------------------------------+----------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"rawPrediction\", \"probability\", \"prediction\", \"trueLabel\").show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the results include rows where the probability for 0 (the first value in the probability vector) is only slightly higher than the probability for 1 (the second value in the probability vector). The default discrimination threshold (the boundary that decides whether a probability is predicted as a 1 or a 0) is set to 0.5; so the prediction with the highest probability is always used, no matter how close to the threshold.\n",
    "\n",
    "And we can see from the results above that for those *truelabel* 1s that we predicted 0s, many of them the problibilty of 1 is just slightly less than the threshold 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Parameters \n",
    "To find the best performing parameters, we can use the **CrossValidator** class to evaluate each combination of parameters defined in a **ParameterGrid** against multiple *folds* of the data split into training and validation datasets. Note that this can take a long time to run because every parameter combination is tried multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Discrimination Threshold\n",
    "The AUC score seems to indicate a reasonably good model, but the performance metrics seem to indicate that it predicts a high number of *False Negative* labels (i.e. it predicts 0 when the true label is 1), leading to a low *Recall*. We can improve this by lowering the threshold. Conversely, sometimes we may want to address a large number of *False Positive* by raising the threshold. \n",
    "\n",
    "In this case, I'll let the **CrossValidator** find the best threshold from 0.45, 0.4 and 0.35, regularization parameter from 0.3 and 0.1, and the maximum number of iterations allowed from 10 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, \n",
    "                                                                                            [0.4, 0.3]).build()\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)\n",
    "\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|            features|prediction|trueLabel|\n",
      "+--------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,105...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,106...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,106...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPrediction = model.transform(test)\n",
    "newPredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "newPredicted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the **rawPrediction** and **probability** values that were previously predicted as 0 are now predicted as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|           61400.0|\n",
      "|       FP|             249.0|\n",
      "|       TN|          649025.0|\n",
      "|       FN|          100164.0|\n",
      "|Precision|0.9959610050446884|\n",
      "|   Recall|0.3800351563467109|\n",
      "|       F1|0.5501471688476925|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recalculate confusion matrix\n",
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr2 = tp2 / (tp2 + fp2)\n",
    "re2 = tp2 / (tp2 + fn2)\n",
    "metrics2 = spark.createDataFrame([\n",
    " (\"TP\", tp2),\n",
    " (\"FP\", fp2),\n",
    " (\"TN\", tn2),\n",
    " (\"FN\", fn2),\n",
    " (\"Precision\", pr2),\n",
    " (\"Recall\", re2),\n",
    " (\"F1\", 2*pr2*re2/(re2+pr2))],[\"metric\", \"value\"])\n",
    "metrics2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.923056629429511\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the Area Under ROC\n",
    "evaluator2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur2 = evaluator.evaluate(prediction)\n",
    "print( \"AUR2 = \", aur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! The new model improves the *Recall* from 0.11 to 0.37, the *F1* score from 0.20 to 0.54, without compromising other metrics.\n",
    "\n",
    "## Next Step\n",
    "\n",
    "There is still much room to improve the model. For example, I can try more options of lower threshold, or use different classfication models, or prepare data better like adding new features. I'll write another one for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
